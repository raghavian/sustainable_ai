{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263e5f75",
   "metadata": {},
   "source": [
    "# EC-NAS Workshop Tutorial\n",
    "\n",
    "Welcome to the **Energy-Consumption Aware NAS (EC-NAS)** tutorial where you will:\n",
    "\n",
    "- Inspect the dataset (unique architectures, ops, epoch budgets)\n",
    "- Query specific architectures\n",
    "- Sample architectures (via dataset hashes)\n",
    "- Implement Random Search\n",
    "- Build a simple evolutionary search algorithm\n",
    "- Extend to a multi-objective objective (accuracy, energy)\n",
    "- Plot Pareto fronts\n",
    "\n",
    "Based on [EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural Architecture Search](https://ieeexplore.ieee.org/document/10448303)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee93610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone --branch demo --depth 1 --recursive https://github.com/pedrambakh/EC-NAS-Bench.git\n",
    "# !pip -q install -e EC-NAS-Bench/\n",
    "\n",
    "# Restart runtime session if on collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493f78bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Setup\n",
    "import os\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
    "\n",
    "# # Restart runtime session if on collab if issues arise with \"no module named ecnas\"\n",
    "\n",
    "from ecnas.api.nasbench101 import ECNASBench\n",
    "\n",
    "# Path is resolved internally by ECNASBench; just provide the filename:\n",
    "# check ecnas/utils/data/tabular_benchmarks for full list of benchmarks\n",
    "dataset = \"energy_7V9E_surrogate.tfrecord\"\n",
    "benchmark = ECNASBench(dataset_file=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59bf61d",
   "metadata": {},
   "source": [
    "# 1) Inspect the dataset (benchmark)\n",
    "\n",
    "Call `benchmark.info()` to see:\n",
    "- total datapoints and unique models\n",
    "- module_vertices distribution and max_edges\n",
    "- available_ops and epoch budgets\n",
    "- aggregate energy/time/CO2eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8a3098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: call info on benchmark\n",
    "benchmark.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383c7d29",
   "metadata": {},
   "source": [
    "# 2) Query a specific model\n",
    "\n",
    "An architecture is a DAG with adjacency matrix $A\\in\\{0,1\\}^{n\\times n}$ and operations vector\n",
    "$L=[\\ell_1,\\ldots,\\ell_n]$ where $\\ell_1=\\text{input}$ and $\\ell_n=\\text{output}$.\n",
    "\n",
    "We’ll use the simple 4-node example:\n",
    "\n",
    "$$\n",
    "A=\\begin{bmatrix}\n",
    "0&1&1&1\\\\\n",
    "0&0&1&1\\\\\n",
    "0&0&0&1\\\\\n",
    "0&0&0&0\n",
    "\\end{bmatrix},\\quad\n",
    "L=[\\text{input},\\ \\text{conv3x3-bn-relu},\\ \\text{conv1x1-bn-relu},\\ \\text{output}].\n",
    "$$\n",
    "\n",
    "Construct a `ModelSpec` and query at `$4$` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b0f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [[0,1,1,1],\n",
    "          [0,0,1,1],\n",
    "          [0,0,0,1],\n",
    "          [0,0,0,0]]\n",
    "labels = [\"input\", \"conv3x3-bn-relu\", \"conv1x1-bn-relu\", \"output\"]\n",
    "\n",
    "model_spec = benchmark.get_model_spec(matrix, labels)\n",
    "metrics = benchmark.query(model_spec, epochs=4)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95205b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try with a different matrix and operations\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530a00d6",
   "metadata": {},
   "source": [
    "# 3) Sampling **existing** architectures (from hashes)\n",
    "\n",
    "Important: Do not fabricate random matrices/ops as they may be disconnected or not in the dataset.  \n",
    "Instead, sample from the dataset’s hashes and reconstruct the spec:\n",
    "\n",
    "1. Draw a hash $h$ from `benchmark.hash_iterator()`.\n",
    "2. Get fixed stats via `benchmark.get_metrics_from_hash(h)`.\n",
    "3. Build a spec using `module_adjacency` and `module_operations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea5bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Helper functions\n",
    "def spec_from_hash(bm, module_hash):\n",
    "    fixed, _ = bm.get_metrics_from_hash(module_hash)\n",
    "    A = fixed[\"module_adjacency\"]\n",
    "    ops = fixed[\"module_operations\"]\n",
    "    A = A.tolist() if isinstance(A, np.ndarray) else A\n",
    "    return bm.get_model_spec(A, ops)\n",
    "\n",
    "def random_spec_from_dataset(bm):\n",
    "    h = random.choice(list(bm.hash_iterator()))\n",
    "    return spec_from_hash(bm, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad6288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: sample and query a random architecture\n",
    "spec = ...\n",
    "data = ...\n",
    "print(\"val_acc =\", data[\"validation_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315e0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Find and display the architecture (matrix + labels) with the highest accuracy, and also the one with the lowest energy consumption\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308e68c4",
   "metadata": {},
   "source": [
    "# 4) Random Search (best-so-far progress)\n",
    "\n",
    "Implement a random search algorithm to explore architectures:\n",
    "\n",
    "For $t=1,\\dots,T$:\n",
    "1. Sample $x_t \\sim \\mathcal{U}(\\text{hashes})$\n",
    "2. Evaluate $f(x_t)=\\text{validation\\_accuracy}(x_t;\\ \\text{epochs}=4)$\n",
    "3. Track best-so-far $b_t=\\max\\{b_{t-1}, f(x_t)\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97462ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def random_search(bm, n_iters=200, epochs=108):\n",
    "    bm.reset_budget_counters()\n",
    "    best, best_val = None, -1.0\n",
    "    hist = []\n",
    "    times = []\n",
    "\n",
    "    # TODO: Implement search logic\n",
    "    for ...\n",
    "        \n",
    "        hist.append(best_val)\n",
    "        t_spent, _ = bm.get_budget_counters() # Return (training_time, epochs)\n",
    "        times.append(t_spent)\n",
    "\n",
    "    return best_val, best, hist, times\n",
    "\n",
    "best_val, best_spec, hist, times = random_search(benchmark, n_iters=40, epochs=4)\n",
    "\n",
    "plt.plot(hist)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Best Validation Accuracy\")\n",
    "plt.title(\"Random Search (existing hashes)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b048fa9a",
   "metadata": {},
   "source": [
    "# 5) (Helper functions) Mutation that stays inside the dataset\n",
    "\n",
    "Evolution needs mutation, but we must ensure the mutated child exists in the benchmark.\n",
    "\n",
    "Strategy:\n",
    "- Start from parent spec $(A,L)$.\n",
    "- Propose a small change (flip one edge or change one op).\n",
    "- Rehash the candidate using the benchmark’s hashing (`_hash_spec`).\n",
    "- Accept the mutation only if the resulting hash is in the dataset.\n",
    "- Retry up to $K$ times; otherwise, fallback to a fresh random hash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269480a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# -- helper: sample an existing spec uniformly at random from the dataset --\n",
    "def random_spec_from_dataset(bm):\n",
    "    h = random.choice(list(bm.hash_iterator()))\n",
    "    fixed, _ = bm.get_metrics_from_hash(h)\n",
    "    A = fixed[\"module_adjacency\"]\n",
    "    ops = fixed[\"module_operations\"]\n",
    "    # ensure types are plain Python lists for ModelSpec\n",
    "    A = A.tolist() if isinstance(A, np.ndarray) else A\n",
    "    return bm.get_model_spec(A, ops)\n",
    "\n",
    "# -- robust single-step random mutation (edge flip OR op change) --\n",
    "def mutate_spec_once_random(bm, spec):\n",
    "    \"\"\"\n",
    "    Randomly flip a single upper-triangular edge OR change one intermediate op.\n",
    "    Returns a syntactic mutation (may or may not exist in the dataset).\n",
    "    \"\"\"\n",
    "    A = np.array(spec.matrix, dtype=int)\n",
    "    ops = list(spec.ops)\n",
    "    n   = len(ops)\n",
    "\n",
    "    # available ops for intermediates (from benchmark config)\n",
    "    avail_ops = list(bm.config[\"available_ops\"])\n",
    "\n",
    "    # choose type based on feasibility\n",
    "    can_change_op = n > 2 and any(\n",
    "        [len([o for o in avail_ops if o != ops[idx]]) > 0 for idx in range(1, n-2+1)]\n",
    "    )\n",
    "    do_op = can_change_op and (random.random() < 0.5)\n",
    "\n",
    "    B = A.copy()\n",
    "    new_ops = ops.copy()\n",
    "\n",
    "    if do_op:\n",
    "        # change one intermediate op\n",
    "        idx = random.randint(1, n-2)\n",
    "        choices = [o for o in avail_ops if o != new_ops[idx]]\n",
    "        if choices:\n",
    "            new_ops[idx] = random.choice(choices)\n",
    "        else:\n",
    "            # fallback to edge flip if no alternative op available\n",
    "            do_op = False\n",
    "\n",
    "    if not do_op:\n",
    "        # flip a single upper-triangular edge\n",
    "        i = random.randint(0, n-2)\n",
    "        j = random.randint(i+1, n-1)\n",
    "        B[i, j] = 1 - B[i, j]\n",
    "\n",
    "    return bm.get_model_spec(B.tolist(), new_ops)\n",
    "\n",
    "# -- dataset-validated mutation: keep trying random mutations until hash exists --\n",
    "def mutate_spec_in_dataset(bm, parent_spec, max_tries=200):\n",
    "    \"\"\"\n",
    "    Returns a child spec that exists in the dataset by repeatedly applying\n",
    "    random single-step mutation and checking the resulting hash against the dataset.\n",
    "    Falls back to a random dataset spec if all tries fail.\n",
    "    \"\"\"\n",
    "    hashes = set(bm.hash_iterator())\n",
    "    parent_hash = bm._hash_spec(parent_spec)\n",
    "\n",
    "    for _ in range(max_tries):\n",
    "        child = mutate_spec_once_random(bm, parent_spec)\n",
    "        try:\n",
    "            h = bm._hash_spec(child)\n",
    "        except Exception:\n",
    "            # e.g., op not in canonical list, or malformed spec — just try again\n",
    "            continue\n",
    "        if h != parent_hash and h in hashes:\n",
    "            return child\n",
    "\n",
    "    # fallback: return a random existing architecture\n",
    "    return random_spec_from_dataset(bm)\n",
    "\n",
    "# quick smoke test\n",
    "p = random_spec_from_dataset(benchmark)\n",
    "c = mutate_spec_in_dataset(benchmark, p)\n",
    "m = benchmark.query(c, epochs=4)\n",
    "print(\"child val_acc =\", m[\"validation_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb9f959",
   "metadata": {},
   "source": [
    "# 6) Evolutionary Search\n",
    "\n",
    "We implement a minimal evolutionary loop over **existing** architectures:\n",
    "\n",
    "- Initialize a population from hashes\n",
    "- At each iteration: pick a parent, mutate (constrained to dataset), evaluate, replace one individual\n",
    "- Track the best validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb631298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "def es(bm, n_iters=80, pop_size=16, epochs=4, max_tries=200):\n",
    "    bm.reset_budget_counters()\n",
    "    # initialize population from the dataset\n",
    "    pop = [random_spec_from_dataset(bm) for _ in range(pop_size)]\n",
    "\n",
    "    best_val = -1.0\n",
    "    best_spec = None\n",
    "    hist, times = [], []\n",
    "\n",
    "    # TODO: evaluate initial pop\n",
    "    ...\n",
    "\n",
    "    # TODO: evolution loop\n",
    "    for _ in tqdm(range(n_iters)):\n",
    "        parent = ...\n",
    "        child  = ...\n",
    "        out    = ...\n",
    "        val    = ...\n",
    "\n",
    "        if val > best_val:\n",
    "            best_val, best_spec = val, child\n",
    "\n",
    "        t_spent, _ = bm.get_budget_counters()\n",
    "        hist.append(best_val); times.append(t_spent)\n",
    "\n",
    "    return best_val, best_spec, hist, times\n",
    "\n",
    "best_val_evo, best_spec_evo, hist_evo, times_evo = es(\n",
    "    benchmark, n_iters=20, pop_size=16, epochs=4, max_tries=200\n",
    ")\n",
    "\n",
    "plt.plot(hist_evo)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Best Validation Accuracy\")\n",
    "plt.title(\"Evolutionary Search\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee1b14",
   "metadata": {},
   "source": [
    "## 8) Baselines: Random Search (RS) and Evolutionary Search (ES)\n",
    "\n",
    "We’ll re-implement two single-objective baselines that only evaluate valid, existing architectures:\n",
    "\n",
    "- RS: sample random specs (uniform over dataset hashes), evaluate; track best-so-far.\n",
    "- ES: fixed-size population; each iteration mutates one parent (using our in-dataset mutation) and replaces a random individual. (No aging / FIFO.)\n",
    "\n",
    "You can plug in any scalar objective $f(m)$ from the metrics `m` returned by `benchmark.query(...)`, e.g.\n",
    "- $f(m)=\\texttt{validation\\_accuracy}$ (maximize),\n",
    "- $f(m)=\\texttt{validation\\_accuracy} - \\lambda\\,\\texttt{energy (kWh)}$.\n",
    "\n",
    "We’ll plot best-so-far objective and best-so-far validation accuracy for RS and ES.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e552813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Baselines: RS and ES (single-objective) ---\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example objectives (edit/extend as you like)\n",
    "OBJECTIVES = {\n",
    "    \"ValAcc\": lambda m: m[\"validation_accuracy\"],\n",
    "    \"Custom\": lambda m: (m[\"validation_accuracy\"] - 0.50 + m[\"energy (kWh)\"]),\n",
    "}\n",
    "\n",
    "def random_search_with_objective(bm, objective_fn, n_evals=200, epochs=4, seed=0):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    bm.reset_budget_counters()\n",
    "\n",
    "    best_score, best_val = -1e9, -1.0\n",
    "    hist_score, hist_val, times = [], [], []\n",
    "\n",
    "    for _ in range(n_evals):\n",
    "        s = random_spec_from_dataset(bm)\n",
    "        out = bm.query(s, epochs=epochs)\n",
    "        score = objective_fn(out)\n",
    "        best_score = max(best_score, score)\n",
    "        best_val   = max(best_val, out[\"validation_accuracy\"])\n",
    "        t_spent, _ = bm.get_budget_counters()\n",
    "        hist_score.append(best_score); hist_val.append(best_val); times.append(t_spent)\n",
    "\n",
    "    return dict(best_score=best_score, hist_score=hist_score,\n",
    "                best_val=best_val, hist_val=hist_val, times=times)\n",
    "\n",
    "def es(bm, objective_fn, n_iters=200, pop_size=16, epochs=4, max_tries=200, seed=0):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    bm.reset_budget_counters()\n",
    "\n",
    "    # init pop from dataset\n",
    "    pop = [random_spec_from_dataset(bm) for _ in range(pop_size)]\n",
    "\n",
    "    best_score, best_val = -1e9, -1.0\n",
    "    hist_score, hist_val, times = [], [], []\n",
    "\n",
    "    # evaluate initial pop\n",
    "    for s in pop:\n",
    "        out = bm.query(s, epochs=epochs)\n",
    "        sc  = objective_fn(out)\n",
    "        if sc > best_score: best_score = sc\n",
    "        if out[\"validation_accuracy\"] > best_val: best_val = out[\"validation_accuracy\"]\n",
    "        t_spent, _ = bm.get_budget_counters()\n",
    "        hist_score.append(best_score); hist_val.append(best_val); times.append(t_spent)\n",
    "\n",
    "    # evolution loop: mutate a random parent; replace a random individual\n",
    "    for _ in range(n_iters):\n",
    "        parent = random.choice(pop)\n",
    "        child  = mutate_spec_in_dataset(bm, parent, max_tries=max_tries)\n",
    "        out    = bm.query(child, epochs=epochs)\n",
    "        sc     = objective_fn(out)\n",
    "\n",
    "        if sc > best_score: best_score = sc\n",
    "        if out[\"validation_accuracy\"] > best_val: best_val = out[\"validation_accuracy\"]\n",
    "\n",
    "        pop[random.randrange(pop_size)] = child  # random replacement\n",
    "\n",
    "        t_spent, _ = bm.get_budget_counters()\n",
    "        hist_score.append(best_score); hist_val.append(best_val); times.append(t_spent)\n",
    "\n",
    "    return dict(best_score=best_score, hist_score=hist_score,\n",
    "                best_val=best_val, hist_val=hist_val, times=times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07dc6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Run both baselines on a chosen objective ----\n",
    "EPOCHS = 108\n",
    "OBJ_NAME = \"Custom\"\n",
    "OBJ = OBJECTIVES[OBJ_NAME]\n",
    "\n",
    "rs_res = random_search_with_objective(benchmark, OBJ, n_evals=250, epochs=EPOCHS, seed=0)\n",
    "es_res = es(benchmark, OBJ, n_iters=200, pop_size=16, epochs=EPOCHS, max_tries=200, seed=0)\n",
    "\n",
    "# ---- Plots ----\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(rs_res[\"hist_score\"], label=f\"RS ({OBJ_NAME})\")\n",
    "plt.plot(es_res[\"hist_score\"], label=f\"ES ({OBJ_NAME})\")\n",
    "plt.title(\"Best-so-far objective\"); plt.xlabel(\"Evaluations\"); plt.ylabel(\"Score\")\n",
    "plt.grid(True); plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(rs_res[\"hist_val\"], label=\"RS\")\n",
    "plt.plot(es_res[\"hist_val\"], label=\"ES\")\n",
    "plt.title(\"Best-so-far validation accuracy\"); plt.xlabel(\"Evaluations\"); plt.ylabel(\"ValAcc\")\n",
    "plt.grid(True); plt.legend()\n",
    "\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a97fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try adding a different objetive and running the algorithms again\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c50a0",
   "metadata": {},
   "source": [
    "## 9) True multi-objective analysis: Pareto dominance (Accuracy vs Energy)\n",
    "\n",
    "We now work in the bi-objective space:\n",
    "$$\\text{maximize} \\quad \\left(\\text{Acc}_\\text{val},\\; -\\,\\text{Energy (kWh)}\\right).$$\n",
    "A point $p = (E_p, A_p)$ is dominated if there exists another point $q$ with\n",
    "$A_q \\ge A_p$ and $E_q \\le E_p$ (and at least one strict inequality). We’ll:\n",
    "\n",
    "1) Sample many existing architectures from the dataset (using their hashes),\n",
    "2) Query at a fixed epoch budget,\n",
    "3) Split them into non-dominated (Pareto-optimal) and dominated, and\n",
    "4) Plot the cloud with the Pareto front highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dominated(p, pts):\n",
    "    for q in pts:\n",
    "        if (q[1] >= p[1]) and (q[0] <= p[0]) and ((q[1] > p[1]) or (q[0] < p[0])):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def pareto_split(points):\n",
    "    nd, dom = [], []\n",
    "    for p in points:\n",
    "        (nd if not dominated(p, points) else dom).append(p)\n",
    "    nd.sort(key=lambda x: x[0])  # sort Pareto front by energy\n",
    "    return nd, dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1005a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample and evaluate\n",
    "N = 100\n",
    "epochs = 108\n",
    "pts = []\n",
    "for _ in range(N):\n",
    "    s = random_spec_from_dataset(benchmark)\n",
    "    o = benchmark.query(s, epochs=epochs)\n",
    "    pts.append((o[\"energy (kWh)\"], o[\"validation_accuracy\"]))\n",
    "\n",
    "front, dominated_pts = pareto_split(pts)\n",
    "\n",
    "# Plot\n",
    "ef, af = zip(*front)\n",
    "if dominated_pts:\n",
    "    ed, ad = zip(*dominated_pts)\n",
    "    plt.scatter(ed, ad, alpha=0.25, label=\"Dominated\", s=18)\n",
    "plt.plot(ef, af, lw=2.5, label=\"Pareto front\")\n",
    "plt.scatter(ef, af, s=30, label=\"Non-dominated\")\n",
    "plt.xlabel(\"Energy (kWh)\"); plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(f\"Pareto front (epochs={epochs})\")\n",
    "plt.legend(); plt.grid(True); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try searching with a different epoch budget and display the pareto front again\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415fe509",
   "metadata": {},
   "source": [
    "# 10) Implement your own algorithm based, perhaps based on non-dominated sorting as in EC-NAS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement your own algorithm\n",
    "def moo_semoa(\n",
    "    bm,\n",
    "    n_iters=200,\n",
    "    pop_size=32,\n",
    "    epochs=108,\n",
    "    max_tries=200,\n",
    "    seed=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    SEMOA-style multi-objective evolutionary search (skeleton).\n",
    "\n",
    "    Dataset-only constraints:\n",
    "      - Initialize population using existing architectures in the benchmark:\n",
    "          random_spec_from_dataset(bm)\n",
    "      - Generate offspring by mutating *into existing* architectures:\n",
    "          mutate_spec_in_dataset(bm, parent_spec, max_tries)\n",
    "      - Evaluate strictly via:\n",
    "          out = bm.query(spec, epochs=epochs)\n",
    "\n",
    "    Objectives (fixed for this notebook):\n",
    "      - Minimize Energy:  E := out[\"energy (kWh)\"]\n",
    "      - Maximize ValAcc: A := out[\"validation_accuracy\"]\n",
    "\n",
    "    Inputs:\n",
    "      bm         : ECNAS benchmark object.\n",
    "      n_iters    : evolution steps (offspring evaluations).\n",
    "      pop_size   : population size.\n",
    "      epochs     : training budget for bm.query.\n",
    "      max_tries  : max tries to find a mutated child that exists in dataset.\n",
    "      seed       : RNG seed.\n",
    "\n",
    "    Required outputs (downstream plotting expects exactly these keys):\n",
    "      return dict(\n",
    "        best_score   = <float>,                  # e.g., |final Pareto set| (size)\n",
    "        hist_score   = <list[float]>,            # running best_score per evaluation\n",
    "        best_val     = <float>,                  # best-so-far validation accuracy\n",
    "        hist_val     = <list[float]>,            # running best_val per evaluation\n",
    "        times        = <list[float]>,            # bm.get_budget_counters() time stamps\n",
    "        points       = <list[tuple(E,A)]>,       # all (Energy, ValAcc) seen by this algo\n",
    "        pareto_front = <list[tuple(E,A)]>,       # final ND set, sorted by Energy asc\n",
    "      )\n",
    "\n",
    "    Implementation guide (fill in yourself):\n",
    "      1) Seed RNGs; bm.reset_budget_counters().\n",
    "      2) Initialize pop with random_spec_from_dataset(bm).\n",
    "      3) Evaluate pop; collect (E,A), update traces (best_val, hist*, times).\n",
    "      4) For t in 1..n_iters:\n",
    "           a) Non-dominated sorting + diversity (your SEMOA/ECNAS flavor).\n",
    "           b) Parent selection from ND ranks (and crowding, if used).\n",
    "           c) child = mutate_spec_in_dataset(bm, parent, max_tries).\n",
    "           d) Evaluate child; environmental selection to keep pop_size.\n",
    "           e) Update traces and append (E,A) to `points`.\n",
    "      5) Compute `pareto_front` from `points` via your ND filter; sort by E.\n",
    "      6) Return the dict above.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Implement SEMOA/ECNAS MOO here.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f431f01a",
   "metadata": {},
   "source": [
    "# 11) Run RS, ES, (optionally) MOO; plot all Pareto fronts over the dataset (or subset thereof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adefba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, numpy as np, matplotlib.pyplot as plt\n",
    "def rs_with_points(bm, n_evals=300, epochs=108, seed=0):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    bm.reset_budget_counters()\n",
    "\n",
    "    best_val = -1.0\n",
    "    hist_score, hist_val, times, points = [], [], [], []\n",
    "\n",
    "    for _ in range(n_evals):\n",
    "        s = random_spec_from_dataset(bm)\n",
    "        out = bm.query(s, epochs=epochs)\n",
    "        E, A = float(out[\"energy (kWh)\"]), float(out[\"validation_accuracy\"])\n",
    "        points.append((E, A))\n",
    "        best_val = max(best_val, A)\n",
    "        t, _ = bm.get_budget_counters()\n",
    "        hist_val.append(best_val); hist_score.append(best_val)  # score := best ValAcc\n",
    "        times.append(t)\n",
    "\n",
    "    # Pareto front of this algorithm's evaluated points\n",
    "    front, _ = pareto_split(points)\n",
    "\n",
    "    return dict(best_score=len(front), hist_score=hist_score,\n",
    "                best_val=best_val, hist_val=hist_val, times=times,\n",
    "                points=points, pareto_front=front)\n",
    "\n",
    "def es_with_points(bm, n_iters=300, pop_size=24, epochs=108, max_tries=200, seed=0):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    bm.reset_budget_counters()\n",
    "\n",
    "    pop = [random_spec_from_dataset(bm) for _ in range(pop_size)]\n",
    "    best_val = -1.0\n",
    "    hist_score, hist_val, times, points = [], [], [], []\n",
    "\n",
    "    # evaluate init pop\n",
    "    for s in pop:\n",
    "        out = bm.query(s, epochs=epochs)\n",
    "        E, A = float(out[\"energy (kWh)\"]), float(out[\"validation_accuracy\"])\n",
    "        points.append((E, A))\n",
    "        best_val = max(best_val, A)\n",
    "        t, _ = bm.get_budget_counters()\n",
    "        hist_val.append(best_val); hist_score.append(best_val); times.append(t)\n",
    "\n",
    "    # loop (age-agnostic replacement)\n",
    "    for _ in range(n_iters):\n",
    "        parent = random.choice(pop)\n",
    "        child  = mutate_spec_in_dataset(bm, parent, max_tries=max_tries)\n",
    "        out    = bm.query(child, epochs=epochs)\n",
    "        E, A   = float(out[\"energy (kWh)\"]), float(out[\"validation_accuracy\"])\n",
    "        points.append((E, A))\n",
    "        best_val = max(best_val, A)\n",
    "        pop[random.randrange(pop_size)] = child\n",
    "\n",
    "        t, _ = bm.get_budget_counters()\n",
    "        hist_val.append(best_val); hist_score.append(best_val); times.append(t)\n",
    "\n",
    "    front, _ = pareto_split(points)\n",
    "\n",
    "    return dict(best_score=len(front), hist_score=hist_score,\n",
    "                best_val=best_val, hist_val=hist_val, times=times,\n",
    "                points=points, pareto_front=front)\n",
    "\n",
    "# ----- Dataset cloud sampler (for visual context only) -----\n",
    "def sample_dataset_cloud(bm, N=10000, epochs=108, seed=123):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    pts = []\n",
    "    for _ in range(N):\n",
    "        s = random_spec_from_dataset(bm)\n",
    "        o = bm.query(s, epochs=epochs)\n",
    "        pts.append((float(o[\"energy (kWh)\"]), float(o[\"validation_accuracy\"])))\n",
    "    return pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881ad4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Run the three algorithms (MOO optional) -----\n",
    "EPOCHS = 108\n",
    "\n",
    "rs_res  = rs_with_points(benchmark, n_evals=300, epochs=EPOCHS, seed=0)\n",
    "es_res  = es_with_points(benchmark, n_iters=300, pop_size=24, epochs=EPOCHS, max_tries=200, seed=0)\n",
    "\n",
    "# Try MOO; if not implemented, carry on with empty result\n",
    "try:\n",
    "    moo_res = moo_semoa(benchmark, n_iters=300, pop_size=32, epochs=36, max_tries=200, seed=0)\n",
    "except NotImplementedError:\n",
    "    moo_res = dict(points=[], pareto_front=[], best_score=0, hist_score=[], best_val=0.0, hist_val=[], times=[])\n",
    "    print(\"[MOO] Not implemented yet — skipping MOO run (RS & ES will still be plotted).\")\n",
    "\n",
    "# ----- Plot all fronts on the same figure over the dataset cloud -----\n",
    "cloud = sample_dataset_cloud(benchmark, N=4000, epochs=EPOCHS, seed=42)\n",
    "Ec, Ac = zip(*cloud)\n",
    "plt.figure(figsize=(8.5,6.5))\n",
    "plt.scatter(Ec, Ac, s=8, alpha=0.10, color=\"#999999\", label=\"Dataset sample\")\n",
    "\n",
    "def plot_front(res, label, color, marker=\"o\"):\n",
    "    if not res[\"pareto_front\"]:\n",
    "        return\n",
    "    E, A = zip(*res[\"pareto_front\"])\n",
    "    plt.plot(E, A, lw=2.2, color=color, label=label)\n",
    "    plt.scatter(E, A, s=26, color=color, marker=marker, edgecolors=\"white\", linewidths=0.6)\n",
    "\n",
    "plot_front(rs_res,  \"RS front\",  \"#d62728\", marker=\"s\")\n",
    "plot_front(es_res,  \"ES front\",  \"#1f77b4\", marker=\"^\")\n",
    "plot_front(moo_res, \"MOO (SEMOA) front\", \"#2ca02c\", marker=\"o\")\n",
    "\n",
    "plt.xlabel(\"Energy (kWh)\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.title(f\"RS vs ES vs MOO (fronts) on dataset cloud\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cfea44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try above code with different parameters (e.g., population size, epochs, etc.) and visualize the results.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e31c89",
   "metadata": {},
   "source": [
    "1. **Why is random search considered a strong baseline in NAS, and how does it relate to exhaustive search?**  \n",
    "   *Answer:* \n",
    "\n",
    "2. **In evolutionary search, why is mutation often sufficient in NAS benchmarks like EC-NAS?**  \n",
    "   *Answer:*\n",
    "\n",
    "3. **What does it mean for one architecture to *dominate* another in the Pareto sense?**  \n",
    "   *Answer:*  \n",
    "\n",
    "4. **Why do we prefer Pareto fronts over scalarized objectives in multi-objective NAS?**  \n",
    "   *Answer:*\n",
    "\n",
    "5. **Why is it important to include energy consumption as an explicit optimization objective in NAS, rather than only reporting accuracy?**  \n",
    "*Answer:*\n",
    "\n",
    "6. **How does the size and structure of the NAS search space influence the performance and fairness of different optimization algorithms?**  \n",
    "*Answer:*\n",
    "\n",
    "7. **Why might two architectures with identical training times consume very different amounts of energy?**  \n",
    "   *Answer:* \n",
    "\n",
    "8. **Why is correlation between training time and energy consumption not sufficient for sustainability analysis?**  \n",
    "   *Answer:*\n",
    "\n",
    "9. **What makes a fair comparison between RS, ES, and MOO on EC-NAS?**  \n",
    "   *Answer:* \n",
    "\n",
    "10. **How does introducing sustainability as an explicit optimization objective change the role of NAS in practice?**  \n",
    "   *Answer:* \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecnas3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
